import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime, timedelta, timezone, time as dt_time
import yfinance as yf
import plotly.graph_objects as go

# ==========================================
# è¨­å®š & ãƒšãƒ¼ã‚¸æ§‹æˆ
# ==========================================
st.set_page_config(layout="wide", page_title="åº•æ‰“ç¢ºèªçµ„")

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
}

JST = timezone(timedelta(hours=9))

# ==========================================
# CSS: ãƒ•ã‚©ãƒ³ãƒˆ & ãƒ‡ã‚¶ã‚¤ãƒ³è¨­å®š
# ==========================================
st.markdown("""
<style>
@import url('https://fonts.googleapis.com/css2?family=Shippori+Mincho+B1:wght@800&display=swap');

h1 {
    font-family: 'Genkai Mincho', 'Shippori Mincho B1', serif !important;
    font-weight: 800 !important;
    font-size: 3.5rem !important;
    text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
}
h3 {
    font-family: 'Hiragino Sans', 'Yu Gothic', sans-serif !important;
    color: gray;
    margin-top: -15px !important;
    font-size: 1.2rem !important;
}
/* è©³ç´°è¡¨ç¤ºï¼ˆ4æœ¬å€¤ï¼‰ã®ã‚¹ã‚¿ã‚¤ãƒ« */
div[data-testid="stMetric"] {
    background-color: #f8f9fa;
    padding: 10px;
    border-radius: 5px;
    border: 1px solid #e0e0e0;
}
</style>
""", unsafe_allow_html=True)

# ==========================================
# é–¢æ•°: ãƒãƒ£ãƒ¼ãƒˆæç”»
# ==========================================
def display_chart(code):
    st.markdown("##### ğŸ“‰ æ ªä¾¡ãƒãƒ£ãƒ¼ãƒˆ")
    tab_d, tab_w, tab_m = st.tabs(["æ—¥è¶³", "é€±è¶³", "æœˆè¶³"])
    ticker_symbol = f"{code}.T"
    
    def plot_candle(period, interval, ma1, ma2, label_ma1, label_ma2, height=350):
        try:
            stock = yf.Ticker(ticker_symbol)
            df = stock.history(period=period, interval=interval)
            if df.empty:
                st.warning("ãƒ‡ãƒ¼ã‚¿ãªã—")
                return
            
            df['MA1'] = df['Close'].rolling(window=ma1).mean()
            df['MA2'] = df['Close'].rolling(window=ma2).mean()

            fig = go.Figure()
            fig.add_trace(go.Candlestick(
                x=df.index, open=df['Open'], high=df['High'], low=df['Low'], close=df['Close'],
                name='æ ªä¾¡', increasing_line_color='#00C805', decreasing_line_color='#FF333A'
            ))
            fig.add_trace(go.Scatter(x=df.index, y=df['MA1'], mode='lines', name=label_ma1, line=dict(color='orange', width=1)))
            fig.add_trace(go.Scatter(x=df.index, y=df['MA2'], mode='lines', name=label_ma2, line=dict(color='skyblue', width=1)))
            
            fig.update_layout(
                height=height, margin=dict(l=10, r=10, t=10, b=10),
                xaxis_rangeslider_visible=False, template="plotly_white", showlegend=True,
                legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1)
            )
            if interval == "1d":
                fig.update_xaxes(rangebreaks=[dict(bounds=["sat", "mon"])])
            st.plotly_chart(fig, use_container_width=True)
        except Exception:
            st.warning("ãƒãƒ£ãƒ¼ãƒˆå–å¾—ã‚¨ãƒ©ãƒ¼")

    with tab_d: plot_candle("1y", "1d", 25, 75, "25æ—¥", "75æ—¥")
    with tab_w: plot_candle("2y", "1wk", 13, 26, "13é€±", "26é€±")
    with tab_m: plot_candle("5y", "1mo", 12, 24, "12æœˆ", "24æœˆ")

# ==========================================
# é–¢æ•°: PDFè¡¨ç¤ºç”¨
# ==========================================
def display_pdf(url):
    viewer_url = f"https://docs.google.com/viewer?url={url}&embedded=true"
    st.markdown(
        f'<iframe src="{viewer_url}" width="100%" height="800" frameborder="0"></iframe>',
        unsafe_allow_html=True
    )

# ==========================================
# é–¢æ•°: TDnetãƒ‡ãƒ¼ã‚¿å–å¾—
# ==========================================
@st.cache_data(ttl=300)
def get_tdnet_data(target_date):
    date_str = target_date.strftime('%Y%m%d')
    base_url = "https://www.release.tdnet.info/inbs/I_list_{}_{}.html"
    root_url = "https://www.release.tdnet.info/inbs/"
    disclosure_map = {}
    page = 1
    while True:
        url = base_url.format(f"{page:03}", date_str)
        try:
            res = requests.get(url, headers=HEADERS, timeout=5)
            if res.status_code == 404: break
            res.encoding = 'utf-8'
            soup = BeautifulSoup(res.text, 'html.parser')
            rows = soup.select("table tr")
            for row in rows:
                cols = row.find_all('td')
                if len(cols) >= 4:
                    code_full = cols[1].text.strip()
                    code_4 = code_full[:4]
                    title = cols[3].text.strip()
                    link_tag = cols[3].find('a')
                    pdf_url = ""
                    if link_tag and 'href' in link_tag.attrs:
                        pdf_url = root_url + link_tag['href']
                    if code_4 not in disclosure_map: disclosure_map[code_4] = []
                    disclosure_map[code_4].append({"time": cols[0].text.strip(), "title": title, "url": pdf_url})
            page += 1
            time.sleep(0.1)
        except: break
    return disclosure_map

# ==========================================
# é–¢æ•°: ãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾— (â˜…å¤‰å‹•é¡è¿½åŠ ç‰ˆ)
# ==========================================
def get_ranking_data_no_cache(mode, threshold, max_items):
    # â€» ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã®ã¿å‘¼ã¶ãŸã‚ cache_data ã¯å¤–ã—ã¦ session_state ã§ç®¡ç†ã™ã‚‹
    candidates = []
    seen_codes = set()
    
    # URLè¨­å®š & ã‚«ãƒ©ãƒ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å®šç¾© (Price, Change, Pct)
    if mode == "PTS": # å¤œé–“PTS
        targets = [
            ("https://kabutan.jp/warning/pts_night_price_increase", "æ€¥é¨°"),
            ("https://kabutan.jp/warning/pts_night_price_decrease", "æ€¥è½")
        ]
        # PTS Warning: 6:Price, 7:Change(å¤‰å‹•é¡), 8:Pct(å¤‰å‹•ç‡)
        idxs = {"code": 0, "name": 1, "market": 2, "price": 6, "change": 7, "pct": 8}
        
    elif mode == "PTS_DAY": # æ—¥ä¸­PTS
        targets = [
            ("https://kabutan.jp/warning/pts_day_price_increase", "æ€¥é¨°"),
            ("https://kabutan.jp/warning/pts_day_price_decrease", "æ€¥è½")
        ]
        # PTS Warning: 6:Price, 7:Change, 8:Pct
        idxs = {"code": 0, "name": 1, "market": 2, "price": 6, "change": 7, "pct": 8}
        
    else: # æ±è¨¼æ—¥ä¸­
        targets = [
            ("https://kabutan.jp/warning/?mode=2_1", "æ€¥é¨°"), # æœ¬æ—¥ã®æ€¥é¨°
            ("https://kabutan.jp/warning/?mode=2_2", "æ€¥è½")  # æœ¬æ—¥ã®æ€¥è½
        ]
        # Ranking Warning: 4:Price, 5:Change, 6:Pct (â€»Warningãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ)
        # æ ªæ¢ã®Warningãƒ¢ãƒ¼ãƒ‰ã¯PTSã¨åŒã˜ã‚«ãƒ©ãƒ æ§‹æˆã®å ´åˆãŒå¤šã„ãŒã€å¿µã®ãŸã‚Price/Change/Pctã®ä½ç½®ã‚’ç¢ºèª
        # Warningãƒ¢ãƒ¼ãƒ‰ã®å ´åˆ: 0:Code, 1:Name, 2:Market, 6:Price, 7:Change, 8:Pct ãŒåŸºæœ¬
        idxs = {"code": 0, "name": 1, "market": 2, "price": 6, "change": 7, "pct": 8}

    progress_text = f"{mode}ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."
    my_bar = st.progress(0, text=progress_text)
    
    for base_url, label in targets:
        page = 1
        keep_fetching = True
        
        while keep_fetching:
            separator = "&" if "?" in base_url else "?"
            url = base_url if page == 1 else f"{base_url}{separator}page={page}"
            if page > 20: break
            
            try:
                time.sleep(0.2)
                res = requests.get(url, headers=HEADERS, timeout=10)
                res.encoding = res.apparent_encoding 
                soup = BeautifulSoup(res.text, 'html.parser')
                table = soup.select_one("table.stock_table")
                
                if not table:
                    keep_fetching = False; continue
                
                tbody = table.find("tbody")
                rows = tbody.find_all("tr") if tbody else table.find_all("tr")[1:]
                
                if not rows:
                    keep_fetching = False; continue
                
                valid_count = 0
                for row in rows:
                    cols = row.find_all(["td", "th"])
                    if len(cols) < max(idxs.values()) + 1: continue
                    
                    try:
                        # å¤‰å‹•ç‡ (Pct)
                        pct_str = cols[idxs["pct"]].text.strip()
                        clean_pct = pct_str.replace("%", "").replace("+", "").replace(",", "")
                        if not clean_pct: continue
                        change_pct = float(clean_pct)
                        
                        if abs(change_pct) < threshold or change_pct == 0: continue
                        
                        # å¤‰å‹•é¡ (Change) â˜…è¿½åŠ 
                        change_str = cols[idxs["change"]].text.strip()
                        # "+10", "-5", "0" ãªã©ã‚’æ•°å€¤åŒ–
                        # æ•°å­—ä»¥å¤–(+, -)ãŒå«ã¾ã‚Œã¦ã„ã¦ã‚‚ float() ã¯å¤‰æ›ã§ããªã„å ´åˆãŒã‚ã‚‹ãŸã‚é™¤å»ç­‰ã¯é©å®œ
                        # æ ªæ¢ã¯ "+10" "-10" è¡¨è¨˜ãªã®ã§ãã®ã¾ã¾ã„ã‘ã‚‹å ´åˆãŒå¤šã„ãŒã€å¿µã®ãŸã‚
                        clean_change = change_str.replace(",", "").replace("+", "") 
                        change_val = float(clean_change) if clean_change.replace("-", "").replace(".", "").isdigit() else 0

                        # ã‚³ãƒ¼ãƒ‰
                        code_col = cols[idxs["code"]]
                        code_tag = code_col.find('a')
                        code = code_tag.text.strip() if code_tag else code_col.text.strip()
                        
                        if code in seen_codes: continue
                        seen_codes.add(code)
                        
                        name = cols[idxs["name"]].text.strip()
                        market = cols[idxs["market"]].text.strip()
                        
                        price_str = cols[idxs["price"]].text.strip()
                        price = float(price_str.replace(",", "")) if price_str.replace(",", "").replace(".", "").isdigit() else 0
                        
                        candidates.append({
                            "Code": code, "Name": name, "Market": market,
                            "Price": price, "Change": change_val, "Change_Pct": change_pct, "Label": label
                        })
                        valid_count += 1
                    except Exception: continue
                
                if valid_count == 0:
                    keep_fetching = False
                else:
                    page += 1
                    my_bar.progress(min(len(candidates), 100), text=f"{label} {page-1}ãƒšãƒ¼ã‚¸ç›®... ({len(candidates)}ä»¶)")
                    if max_items > 0 and len(candidates) >= max_items * 2: keep_fetching = False
            except: keep_fetching = False
            
    my_bar.empty()
    return pd.DataFrame(candidates)

# ==========================================
# é–¢æ•°: æ—¥ä¸­4æœ¬å€¤
# ==========================================
def get_daily_ohlc(code):
    url = f"https://kabutan.jp/stock/?code={code}"
    d = {"Open": "-", "High": "-", "Low": "-", "Close": "-"}
    try:
        res = requests.get(url, headers=HEADERS, timeout=5)
        soup = BeautifulSoup(res.text, 'html.parser')
        def find_val(label):
            th = soup.find("th", string=label)
            if th:
                td = th.find_next_sibling("td")
                if td: return td.text.strip()
            return "-"
        d["Open"] = find_val("å§‹å€¤"); d["High"] = find_val("é«˜å€¤")
        d["Low"] = find_val("å®‰å€¤"); d["Close"] = find_val("çµ‚å€¤")
        if d["Close"] == "-":
            span = soup.select_one("span.kabuka")
            if span: d["Close"] = span.text.strip()
        return d
    except: return d

# ==========================================
# UIæ§‹ç¯‰: ã‚µã‚¤ãƒ‰ãƒãƒ¼
# ==========================================
st.sidebar.header("ğŸ” æ¤œç´¢æ¡ä»¶è¨­å®š")

search_mode_raw = st.sidebar.radio(
    "å¯¾è±¡å¸‚å ´ãƒ»æ™‚é–“",
    ["PTS (å¤œé–“)", "PTS (æ—¥ä¸­)", "æ—¥ä¸­ (æ±è¨¼ã‚¶ãƒ©å ´/å¤§å¼•ã‘)"],
    index=0
)

now_jst = datetime.now(JST)
current_time = now_jst.time()
market_open = dt_time(9, 0)
market_close = dt_time(15, 30) 

if "PTS (å¤œé–“)" in search_mode_raw:
    mode_key = "PTS"
    display_mode_label = "PTS (å¤œé–“ğŸŒ™)"
elif "PTS (æ—¥ä¸­)" in search_mode_raw:
    mode_key = "PTS_DAY"
    display_mode_label = "PTS (æ—¥ä¸­â˜€ï¸)"
else:
    mode_key = "Daytime"
    if market_open <= current_time < market_close:
        display_mode_label = "æ±è¨¼ (ã‚¶ãƒ©å ´ ğŸ”´Realtime)"
    else:
        display_mode_label = "æ±è¨¼ (å¤§å¼•ã‘ ğŸFinal)"

search_date = st.sidebar.date_input("TDnetæ¤œç´¢æ—¥", value=now_jst.date())

st.sidebar.subheader(f"{display_mode_label} è¨­å®š")
threshold_percent = st.sidebar.slider("å¤‰å‹•ç‡ é–¾å€¤ (%)", 0.0, 20.0, 3.0, 0.1)
col_p1, col_p2 = st.sidebar.columns(2)
min_price = col_p1.number_input("ä¸‹é™ (å††)", value=0, step=100)
max_price = col_p2.number_input("ä¸Šé™ (å††)", value=0, step=100)
max_items = st.sidebar.number_input("æ¤œç´¢ä¸Šé™æ•°", value=0, step=10)

filter_news = st.sidebar.checkbox("ğŸ“„ é©æ™‚é–‹ç¤ºã‚ã‚Šã®éŠ˜æŸ„ã®ã¿è¡¨ç¤º", value=False)

st.sidebar.divider()
# â˜…æ›´æ–°ãƒœã‚¿ãƒ³: session_stateã‚’ä½¿ã£ã¦ãƒ‡ãƒ¼ã‚¿ä¿æŒã‚’ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ«
update_clicked = st.sidebar.button("ãƒ‡ãƒ¼ã‚¿æ›´æ–° / ãƒªãƒ­ãƒ¼ãƒ‰", type="primary")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆåˆæœŸåŒ–
if 'ranking_df' not in st.session_state:
    st.session_state['ranking_df'] = pd.DataFrame()
if 'last_update' not in st.session_state:
    st.session_state['last_update'] = None

# ==========================================
# UIæ§‹ç¯‰: ãƒ¡ã‚¤ãƒ³ç”»é¢
# ==========================================
st.title("åº•æ‰“ç¢ºèªçµ„")
st.subheader(f"{display_mode_label} å¤‰å‹• & é©æ™‚é–‹ç¤ºãƒ¢ãƒ‹ã‚¿ãƒ¼")

# --- ãƒ‡ãƒ¼ã‚¿å‡¦ç† (ãƒœã‚¿ãƒ³æŠ¼ä¸‹æ™‚ã®ã¿å®Ÿè¡Œ) ---
if update_clicked:
    with st.spinner(f'{search_date.strftime("%Y/%m/%d")} ã®ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...'):
        # TDnetã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ã£ã¦OKã ãŒã€ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã¯éƒ½åº¦å–ã‚‹
        tdnet_data = get_tdnet_data(search_date) # ã‚­ãƒ£ãƒƒã‚·ãƒ¥åŠ¹ã
        raw_df = get_ranking_data_no_cache(mode_key, threshold_percent, max_items)
        
        # å‡¦ç†çµæœã‚’session_stateã«ä¿å­˜
        st.session_state['ranking_df'] = raw_df
        st.session_state['tdnet_data'] = tdnet_data # ãƒ•ã‚£ãƒ«ã‚¿ç”¨
        st.session_state['last_update'] = datetime.now(JST).strftime("%H:%M:%S")

# ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®è¡¨ç¤ºå‡¦ç†
df_result = st.session_state['ranking_df']
tdnet_data = st.session_state.get('tdnet_data', {})

if not df_result.empty:
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° (è¡¨ç¤ºæ™‚ã«è¡Œã†ã“ã¨ã§ã€ãƒ‡ãƒ¼ã‚¿å†å–å¾—ã›ãšã«çµã‚Šè¾¼ã¿å¯èƒ½)
    # 1. ä¾¡æ ¼ãƒ•ã‚£ãƒ«ã‚¿
    if min_price > 0: df_result = df_result[df_result["Price"] >= min_price]
    if max_price > 0: df_result = df_result[df_result["Price"] <= max_price]
    
    # 2. Newsåˆ—
    df_result["News"] = df_result["Code"].apply(lambda x: "ğŸ“„ã‚ã‚Š" if x in tdnet_data else "")

    # 3. é–‹ç¤ºã‚ã‚Šãƒ•ã‚£ãƒ«ã‚¿
    if filter_news:
        df_result = df_result[df_result["News"] == "ğŸ“„ã‚ã‚Š"]

    # 4. ã‚½ãƒ¼ãƒˆ
    if not df_result.empty:
        df_result = df_result.reindex(df_result["Change_Pct"].abs().sort_values(ascending=False).index)
    
    # 5. ä»¶æ•°åˆ¶é™
    if max_items > 0: df_result = df_result.head(max_items)

col_L, col_R = st.columns([1, 1])

with col_L:
    st.subheader(f"{display_mode_label} ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
    if st.session_state['last_update']:
        st.caption(f"æœ€çµ‚æ›´æ–°: {st.session_state['last_update']}")
        
    if not df_result.empty:
        limit_txt = f"ä¸Šä½{max_items}ä»¶" if max_items > 0 else "å…¨ä»¶"
        st.caption(f"é–¾å€¤: Â±{threshold_percent}% | è¡¨ç¤º: {limit_txt} | Hits: {len(df_result)}")
        
        # â˜…Change(å¤‰å‹•é¡)ã‚’è¿½åŠ è¡¨ç¤º
        show_df = df_result[["Code", "Name", "Market", "Price", "Change", "Change_Pct", "News", "Label"]]
        
        event = st.dataframe(
            show_df.style.format({
                "Change_Pct": "{:.2f}%", 
                "Price": "{:,.0f}",
                "Change": "{:+,.0f}" # ãƒ—ãƒ©ã‚¹ç¬¦å·ä»˜ãã§è¡¨ç¤º
            }).map(
                lambda x: 'color: red;' if x < 0 else 'color: green;', subset=['Change_Pct', 'Change']
            ),
            use_container_width=True, hide_index=True, on_select="rerun", selection_mode="single-row", height=700
        )
        selected_rows = event.selection.rows
        sel_code = show_df.iloc[selected_rows[0]]["Code"] if selected_rows else None
        sel_name = show_df.iloc[selected_rows[0]]["Name"] if selected_rows else None
    else:
        st.warning("è©²å½“ãªã— (ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚’æŠ¼ã™ã‹ã€æ¡ä»¶ã‚’ç·©ã‚ã¦ãã ã•ã„)"); sel_code = None

with col_R:
    d_lbl = search_date.strftime("%Y/%m/%d")
    st.subheader(f"è©³ç´° & é–‹ç¤º ({d_lbl})")
    
    if sel_code:
        st.markdown(f"### {sel_code} {sel_name}")

        tv_url = f"https://www.tradingview.com/chart/?symbol=TSE:{sel_code}"
        st.markdown(f'<a href="{tv_url}" target="_blank" style="text-decoration:none;"><button style="margin: 5px; padding: 5px 10px; border-radius: 5px; border: 1px solid #ccc;">ğŸ“ˆ TradingViewã§é–‹ã</button></a>', unsafe_allow_html=True)
        
        display_chart(sel_code)

        with st.spinner('è©³ç´°å–å¾—ä¸­...'): ohlc = get_daily_ohlc(sel_code)
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("å§‹å€¤", ohlc["Open"]); c2.metric("é«˜å€¤", ohlc["High"])
        c3.metric("å®‰å€¤", ohlc["Low"]); c4.metric("çµ‚å€¤", ohlc["Close"])
        st.divider()
        
        if sel_code in tdnet_data:
            st.markdown("##### ğŸ”— å¤–éƒ¨ã‚µã‚¤ãƒˆã§ç¢ºèª")
            lnk1, lnk2, lnk3 = st.columns(3)
            lnk1.link_button("Yahoo!æ²ç¤ºæ¿", f"https://finance.yahoo.co.jp/quote/{sel_code}.T/bbs", use_container_width=True)
            lnk2.link_button("æ ªæ¢ (Kabutan)", f"https://kabutan.jp/stock/?code={sel_code}", use_container_width=True)
            lnk3.link_button("å››å­£å ±ã‚ªãƒ³ãƒ©ã‚¤ãƒ³", f"https://shikiho.toyokeizai.net/stocks/{sel_code}", use_container_width=True)
            
            st.divider()

            news = tdnet_data[sel_code]
            st.success(f"é–‹ç¤º: {len(news)} ä»¶")
            tabs = st.tabs([f"{n['time']}" for n in news])
            for i, t in enumerate(tabs):
                with t:
                    st.markdown(f"**{news[i]['title']}**")
                    if news[i]['url']:
                        st.link_button("â†— PDFã‚’é–‹ã", news[i]['url'])
                        display_pdf(news[i]['url'])
        else:
            st.info("é–‹ç¤ºãªã—")
            st.markdown(f"[Yahoo!æ²ç¤ºæ¿](https://finance.yahoo.co.jp/quote/{sel_code}.T/bbs)")
    else:
        st.info("ğŸ‘ˆ éŠ˜æŸ„ã‚’é¸æŠ")