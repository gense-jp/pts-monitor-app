import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
from datetime import datetime
import base64

# ==========================================
# è¨­å®š
# ==========================================
st.set_page_config(layout="wide", page_title="PTS & TDnet Monitor")
THRESHOLD_PERCENT = 3.0
HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36"
}

# ==========================================
# é–¢æ•°: PDFã‚’è¡¨ç¤ºã™ã‚‹ãŸã‚ã®ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
# ==========================================
def display_pdf(url):
    """
    URLã‹ã‚‰PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã€Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ã—ã¦iframeã§è¡¨ç¤ºã™ã‚‹
    (TDnetã®iframeãƒ–ãƒ­ãƒƒã‚¯å›é¿ã®ãŸã‚)
    """
    try:
        response = requests.get(url, headers=HEADERS)
        if response.status_code == 200:
            # ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’Base64æ–‡å­—åˆ—ã«å¤‰æ›
            base64_pdf = base64.b64encode(response.content).decode('utf-8')
            # iframeã‚¿ã‚°ã‚’ä½œæˆ
            pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="100%" height="800" type="application/pdf"></iframe>'
            # è¡¨ç¤º
            st.markdown(pdf_display, unsafe_allow_html=True)
        else:
            st.error("PDFã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

# ==========================================
# é–¢æ•°: TDnetãƒ‡ãƒ¼ã‚¿å–å¾—
# ==========================================
@st.cache_data(ttl=300)
def get_todays_tdnet_data():
    date_str = datetime.now().strftime('%Y%m%d')
    base_url = "https://www.release.tdnet.info/inbs/I_list_{}_{}.html"
    root_url = "https://www.release.tdnet.info/inbs/"
    
    disclosure_map = {}
    page = 1
    
    while True:
        url = base_url.format(f"{page:03}", date_str)
        try:
            res = requests.get(url, headers=HEADERS, timeout=5)
            if res.status_code == 404: break
            
            res.encoding = 'utf-8' # æ–‡å­—åŒ–ã‘å¯¾ç­–
            
            soup = BeautifulSoup(res.text, 'html.parser')
            rows = soup.select("table tr")
            
            for row in rows:
                cols = row.find_all('td')
                if len(cols) >= 4:
                    code_full = cols[1].text.strip()
                    code_4 = code_full[:4]
                    title = cols[3].text.strip()
                    
                    link_tag = cols[3].find('a')
                    pdf_url = ""
                    if link_tag and 'href' in link_tag.attrs:
                        pdf_url = root_url + link_tag['href']
                    
                    if code_4 not in disclosure_map:
                        disclosure_map[code_4] = []
                    
                    disclosure_map[code_4].append({
                        "time": cols[0].text.strip(),
                        "title": title,
                        "url": pdf_url
                    })
            page += 1
            time.sleep(0.1)
        except: break
    return disclosure_map

# ==========================================
# é–¢æ•°: PTSãƒ©ãƒ³ã‚­ãƒ³ã‚°å–å¾—
# ==========================================
@st.cache_data(ttl=60)
def get_ranking_data():
    candidates = []
    targets = [
        ("https://kabutan.jp/warning/pts_night_price_increase", "æ€¥é¨°"),
        ("https://kabutan.jp/warning/pts_night_price_decrease", "æ€¥è½")
    ]
    
    progress_text = "PTSãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."
    my_bar = st.progress(0, text=progress_text)
    
    for url, label in targets:
        try:
            res = requests.get(url, headers=HEADERS, timeout=10)
            res.encoding = res.apparent_encoding 
            
            soup = BeautifulSoup(res.text, 'html.parser')
            table = soup.select_one("table.stock_table")
            if not table: continue
            
            tbody = table.find("tbody")
            if tbody:
                rows = tbody.find_all("tr")
            else:
                rows = table.find_all("tr")[2:]
            
            for row in rows:
                cols = row.find_all(["td", "th"])
                if len(cols) < 10: continue
                
                try:
                    pct_str = cols[8].text.strip()
                    clean_pct = pct_str.replace("%", "").replace("+", "").replace(",", "")
                    if not clean_pct: continue
                    change_pct = float(clean_pct)
                    
                    if abs(change_pct) >= THRESHOLD_PERCENT:
                        code_tag = cols[0].find('a')
                        code = code_tag.text.strip() if code_tag else cols[0].text.strip()
                        name = cols[1].text.strip()
                        pts_price = cols[6].text.strip()
                        
                        # æ—¥ä¸­è¶³ã¯è©³ç´°è¡¨ç¤ºæ™‚ã«å–å¾—ã™ã‚‹å½¢ã‚‚å¯ã ãŒã€ä¸€è¦§ã§è¦‹ãŸã„è¦æœ›ã«åˆã‚ã›ã¦ç¶­æŒ
                        # â€»é«˜é€ŸåŒ–ã®ãŸã‚ã€ã“ã“ã§ã¯ã€Œå–å¾—ã—ãªã„ã€é¸æŠè‚¢ã‚‚ã‚ã‚Šã¾ã™ãŒã€è¦æœ›é€šã‚Šå–å¾—ã—ã¾ã™
                        # æœ¬æ ¼é‹ç”¨ã§é‡ã„å ´åˆã¯ã€ã“ã“ã§ã®get_daily_ohlcã‚’å‰Šé™¤ã—ã¦ãã ã•ã„
                        candidates.append({
                            "Code": code,
                            "Name": name,
                            "PTS_Price": pts_price,
                            "Change_Pct": change_pct,
                            "Label": label
                        })
                except: continue
        except: continue
        
    my_bar.empty()
    return pd.DataFrame(candidates)

# ==========================================
# é–¢æ•°: æ—¥ä¸­4æœ¬å€¤ (å¿…è¦æ™‚ã«å–å¾—)
# ==========================================
def get_daily_ohlc(code):
    url = f"https://kabutan.jp/stock/?code={code}"
    d = {"Open": "-", "High": "-", "Low": "-", "Close": "-"}
    try:
        res = requests.get(url, headers=HEADERS, timeout=5)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        def find_val(label):
            th = soup.find("th", string=label)
            if th:
                td = th.find_next_sibling("td")
                if td: return td.text.strip()
            return "-"

        d["Open"] = find_val("å§‹å€¤")
        d["High"] = find_val("é«˜å€¤")
        d["Low"] = find_val("å®‰å€¤")
        d["Close"] = find_val("çµ‚å€¤")
        if d["Close"] == "-":
            span = soup.select_one("span.kabuka")
            if span: d["Close"] = span.text.strip()
        return d
    except: return d


# ==========================================
# ãƒ¡ã‚¤ãƒ³ç”»é¢
# ==========================================
st.title("ğŸ“Š PTSæ€¥å‹•æ„ & é©æ™‚é–‹ç¤ºãƒ¢ãƒ‹ã‚¿ãƒ¼")

with st.spinner('ãƒ‡ãƒ¼ã‚¿åé›†ä¸­...'):
    tdnet_data = get_todays_tdnet_data()
    df_pts = get_ranking_data()

# å·¦ï¼šä¸€è¦§è¡¨ã€å³ï¼šPDFãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
col_left, col_right = st.columns([1, 1]) 

with col_left:
    st.subheader("PTS ãƒ©ãƒ³ã‚­ãƒ³ã‚° (Â±3%ä»¥ä¸Š)")
    
    if not df_pts.empty:
        df_pts["News"] = df_pts["Code"].apply(lambda x: "ğŸ“„ã‚ã‚Š" if x in tdnet_data else "")
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«è¡¨ç¤º
        display_df = df_pts[["Code", "Name", "PTS_Price", "Change_Pct", "News", "Label"]]
        
        event = st.dataframe(
            display_df.style.format({"Change_Pct": "{:.2f}%"}).map(
                lambda x: 'color: red;' if x < 0 else 'color: green;', subset=['Change_Pct']
            ),
            use_container_width=True,
            hide_index=True,
            on_select="rerun",
            selection_mode="single-row",
            height=600 # é«˜ã•ã‚’æŒ‡å®šã—ã¦ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã‚„ã™ã
        )
        
        selected_rows = event.selection.rows
        if selected_rows:
            idx = selected_rows[0]
            selected_code = display_df.iloc[idx]["Code"]
            selected_name = display_df.iloc[idx]["Name"]
        else:
            selected_code = None
    else:
        st.info("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹éŠ˜æŸ„ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
        selected_code = None

with col_right:
    st.subheader("è©³ç´° & é©æ™‚é–‹ç¤ºãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
    
    if selected_code:
        # ãƒ˜ãƒƒãƒ€ãƒ¼æƒ…å ±
        st.markdown(f"### {selected_code} {selected_name}")
        
        # 4æœ¬å€¤ã‚’ã“ã“ã§å–å¾—ã—ã¦è¡¨ç¤º (ä¸€è¦§å–å¾—ã®é«˜é€ŸåŒ–ã®ãŸã‚åˆ†é›¢æ¨å¥¨ã ãŒã€ã”è¦æœ›ã‚ã‚Œã°çµ±åˆã‚‚å¯)
        # ã“ã“ã§ã¯ã‚¯ãƒªãƒƒã‚¯æ™‚ã«å–å¾—ã™ã‚‹æ–¹å¼ã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è‰¯ãã—ã¾ã™
        with st.spinner('æ ªä¾¡è©³ç´°ã‚’å–å¾—ä¸­...'):
            ohlc = get_daily_ohlc(selected_code)
            
        # 4æœ¬å€¤ã‚’æ¨ªä¸¦ã³ã§è¡¨ç¤º
        c1, c2, c3, c4 = st.columns(4)
        c1.metric("å§‹å€¤", ohlc["Open"])
        c2.metric("é«˜å€¤", ohlc["High"])
        c3.metric("å®‰å€¤", ohlc["Low"])
        c4.metric("çµ‚å€¤", ohlc["Close"])
        
        st.divider()

        # é–‹ç¤ºæƒ…å ±ã®è¡¨ç¤º
        if selected_code in tdnet_data:
            news_list = tdnet_data[selected_code]
            st.success(f"æœ¬æ—¥ {len(news_list)} ä»¶ã®é–‹ç¤ºãŒã‚ã‚Šã¾ã™")
            
            # ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¤‡æ•°ã‚ã‚‹å ´åˆã¯ã‚¿ãƒ–ã§åˆ‡ã‚Šæ›¿ãˆ
            tabs = st.tabs([f"{n['time']} {n['title'][:10]}..." for n in news_list])
            
            for i, tab in enumerate(tabs):
                news = news_list[i]
                with tab:
                    st.markdown(f"**{news['title']}**")
                    
                    if news['url']:
                        # åˆ¥ã‚¿ãƒ–ã§é–‹ããƒœã‚¿ãƒ³
                        st.link_button("â†— åˆ¥ã‚¿ãƒ–ã§PDFã‚’é–‹ã", news['url'])
                        
                        # åŸ‹ã‚è¾¼ã¿PDFè¡¨ç¤º
                        with st.spinner('PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦è¡¨ç¤ºä¸­...'):
                            display_pdf(news['url'])
                    else:
                        st.warning("PDFãƒªãƒ³ã‚¯ãŒã‚ã‚Šã¾ã›ã‚“")
        else:
            st.info("æœ¬æ—¥ã®é©æ™‚é–‹ç¤ºã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")
            st.markdown(f"â€¢ [Yahoo!æ²ç¤ºæ¿](https://finance.yahoo.co.jp/quote/{selected_code}.T/bbs)")

    else:
        st.info("ğŸ‘ˆ å·¦å´ã®è¡¨ã‹ã‚‰éŠ˜æŸ„ã‚’é¸æŠã—ã¦ãã ã•ã„")

st.divider()
if st.button("ãƒ‡ãƒ¼ã‚¿æ›´æ–°"):
    st.cache_data.clear()
    st.rerun()